{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3f183ce",
   "metadata": {},
   "source": [
    "# Sectora Horizon\n",
    "---\n",
    "A Future-Focused Analytics System for Industries and Busisness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1038a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ingest.catalog import DatasetCatalog\n",
    "from ingest.loader import RawDatasetLoader\n",
    "from utils.uuid import generate_deterministic_id_name_based\n",
    "from utils.clean import clean_text, is_numeric_string, normalize_code_to_length, normalize_text\n",
    "from ingest.fetch.csv import CsvAdapter\n",
    "from ingest.fetch.sct import SocrataAdapter\n",
    "from ingest.fetch.excel import ExcelAdapter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "catalog = DatasetCatalog()\n",
    "loader = RawDatasetLoader(\n",
    "    csv_adapter=CsvAdapter(),\n",
    "    sct_adapter=SocrataAdapter(),\n",
    "    excel_adapter=ExcelAdapter(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "378ea3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = catalog.get(\"master_csv\")\n",
    "records = list(loader.load(ds))\n",
    "df = pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "830ef7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPI columns: ['year', 'CPI']\n",
      "Missing CPI after merge: 0 rows\n"
     ]
    }
   ],
   "source": [
    "# El CSV debe tener columnas: 'year' y 'CPI' (índice anual)\n",
    "cpi_ds = catalog.get(\"IPCanal\")\n",
    "records = list(loader.load(cpi_ds))\n",
    "cpi = pd.DataFrame(records)\n",
    "cpi\n",
    "\n",
    "# normalizar nombres de columnas comunes\n",
    "if 'Año de Corte'  in cpi.columns and 'year' not in cpi.columns:\n",
    "    cpi = cpi.rename(columns={'Año de Corte':'year'})\n",
    "if 'CPI' not in cpi.columns:\n",
    "    # intentar detectar la columna de índice de precios\n",
    "    possible = [c for c in cpi.columns if 'cpi' in c.lower() or 'ipc' in c.lower() or 'indice' in c.lower()]\n",
    "    if possible:\n",
    "        cpi = cpi.rename(columns={possible[0]:'CPI'})\n",
    "cpi.columns = cpi.columns.map(lambda x: x.encode('utf-8').decode('utf-8-sig').strip())\n",
    "print('CPI columns:', cpi.columns.tolist())\n",
    "# merge\n",
    "df = df.merge(cpi[['year','CPI']], on='year', how='left')\n",
    "missing_cpi = df['CPI'].isnull().sum()\n",
    "print(f'Missing CPI after merge: {missing_cpi} rows')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5b9ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ajustadas 40000 filas de GANANCIA a precios del año 2024.\n"
     ]
    }
   ],
   "source": [
    "# 2) Ajustar GANANCIA por inflación a precios del año base (último año disponible)\n",
    "if 'CPI' in df.columns and df['CPI'].notna().any():\n",
    "    # Limpiar CPI: convertir strings con comas a float (ej. '9,28' -> 9.28)\n",
    "    def clean_cpi_value(val):\n",
    "        if pd.isna(val):\n",
    "            return pd.NA\n",
    "        try:\n",
    "            s = str(val).strip().replace(',', '.')\n",
    "            return float(s)\n",
    "        except Exception:\n",
    "            return pd.NA\n",
    "    df['CPI'] = df['CPI'].apply(clean_cpi_value)\n",
    "    base_year = df['year'].max()\n",
    "    base_cpi = df.loc[df['year'] == base_year, 'CPI'].dropna().unique()\n",
    "    if len(base_cpi)==0:\n",
    "        raise ValueError(f'No hay CPI para el año base {base_year}. Revisa el CSV de CPI.')\n",
    "    base_cpi = float(clean_cpi_value(base_cpi[0]))\n",
    "    # Convert temporalely 'ganancias' to numeric\n",
    "    ganancias_num = df['ganancias'].astype(int)\n",
    "    adjusted = ganancias_num * (base_cpi / df['CPI'])\n",
    "    n_adjusted = int(adjusted.notna().sum())\n",
    "    df['ganancias'] = adjusted\n",
    "    print(f\"Ajustadas {n_adjusted} filas de GANANCIA a precios del año {base_year}.\")\n",
    "else:\n",
    "    print('No se puede ajustar por inflación: falta columna CPI.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8324eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lags y target creados.\n",
      "  Filas con ganancias_next válido: 26024\n",
      "  Filas con ganancia_lag_1 válido: 26024\n",
      "  Filas con al menos 1 lag: 26024\n",
      "  Distribución de n_ganancia_lags:\n",
      "n_ganancia_lags\n",
      "0    13976\n",
      "1    11026\n",
      "2     8442\n",
      "3     6556\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 3) Construir target t+1 y lags por NIT (ignorar gaps entre años)\n",
    "df = df.sort_values(['nit','year']).reset_index(drop=True)\n",
    "\n",
    "# target: GANANCIA_REAL del siguiente año disponible para cada NIT (ignora gaps)\n",
    "df['ganancias_next'] = df.groupby('nit')['ganancias'].shift(-1)\n",
    "\n",
    "# fix data type if required\n",
    "if df['ingresos'].dtype in [str, object]:\n",
    "    df['ingresos'] = df['ingresos'].astype(int)\n",
    "\n",
    "# crear lags para ganacias e INGRESOS OPERACIONALES (todos los registros previos de la empresa)\n",
    "for lag in range(1, 5):\n",
    "    df[f'ganancia_lag_{lag}'] = df.groupby('nit')['ganancias'].shift(lag)\n",
    "    df[f'ingresos_lag_{lag}'] = df.groupby('nit')['ingresos'].shift(lag)\n",
    "\n",
    "# contar lags disponibles y crear indicador\n",
    "df['n_ganancia_lags'] = df[[f'ganancia_lag_{i}' for i in range(1,5)]].notna().sum(axis=1)\n",
    "df['n_ingresos_lags'] = df[[f'ingresos_lag_{i}' for i in range(1,5)]].notna().sum(axis=1)\n",
    "\n",
    "# features adicionales: tasa de crecimiento 1 año (si existe lag_1) y media movil de 3 años\n",
    "df['ganancia_grow_1y'] = df['ganancias'] / df['ganancia_lag_1'] - 1\n",
    "df['ganancia_roll_mean_3'] = df.groupby('nit')['ganancias'].transform(lambda s: s.shift(1).rolling(3, min_periods=1).mean())\n",
    "\n",
    "# preservar flag de outlier ya marcado\n",
    "if 'is_outlier_kde' not in df.columns:\n",
    "    df['is_outlier_kde'] = False\n",
    "\n",
    "# Diagnóstico de target y lags\n",
    "n_with_target = df['ganancias_next'].notna().sum()\n",
    "n_with_lag1 = df['ganancia_lag_1'].notna().sum()\n",
    "n_with_any_lag = (df['n_ganancia_lags'] > 0).sum()\n",
    "\n",
    "print(f'Lags y target creados.')\n",
    "print(f'  Filas con ganancias_next válido: {n_with_target}')\n",
    "print(f'  Filas con ganancia_lag_1 válido: {n_with_lag1}')\n",
    "print(f'  Filas con al menos 1 lag: {n_with_any_lag}')\n",
    "print(f'  Distribución de n_ganancia_lags:')\n",
    "print(df['n_ganancia_lags'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c00221f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas disponibles para entrenamiento/evaluación: 26024\n"
     ]
    }
   ],
   "source": [
    "# 4) Preparar dataset para modelado (no excluimos empresas; solo filas sin target se ignoran en entrenamiento)\n",
    "feature_cols = [f'ganancia_lag_{i}' for i in range(1,5)] + [f'ingresos_lag_{i}' for i in range(1,5)] + ['n_ganancia_lags','n_ingresos_lags','ganancia_roll_mean_3','is_outlier_kde']\n",
    "# añadir algunas columnas numéricas originales si interesa\n",
    "for add in ['activos','pasivos','patrimonio']:\n",
    "    if add in df.columns:\n",
    "        feature_cols.append(add)\n",
    "\n",
    "df_model = df[df['ganancias_next'].notna()].copy()  # filas con target t+1 disponibles\n",
    "print('Filas disponibles para entrenamiento/evaluación:', df_model.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3ed312",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb372e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added profit margin from lag_1\n",
      "Added profit volatility feature\n",
      "Added 2 size category dummies\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '21.0'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 49\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m X_new\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m X_new[col]\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 49\u001b[0m         X_new[col] \u001b[38;5;241m=\u001b[39m \u001b[43mX_new\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         X_new[col] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_numeric(X_new[col], errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/generic.py:6643\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   6637\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   6638\u001b[0m         ser\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   6639\u001b[0m     ]\n\u001b[1;32m   6641\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6642\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[0;32m-> 6643\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6644\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m   6645\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/internals/managers.py:430\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    428\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 430\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mastype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/internals/managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/internals/blocks.py:758\u001b[0m, in \u001b[0;36mBlock.astype\u001b[0;34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan not squeeze with more than one column.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    756\u001b[0m     values \u001b[38;5;241m=\u001b[39m values[\u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[0;32m--> 758\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    760\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[1;32m    762\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:237\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[0;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    234\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 237\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:182\u001b[0m, in \u001b[0;36mastype_array\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m    179\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 182\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43m_astype_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:133\u001b[0m, in \u001b[0;36m_astype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mor\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;66;03m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: '21.0'"
     ]
    }
   ],
   "source": [
    "df_features = df_model.copy()\n",
    "\n",
    "# A) Add sector dummies (companies in same sector may have similar patterns)\n",
    "if 'macrosector' in df_features.columns:\n",
    "    sector_dummies = pd.get_dummies(df_features['macrosector'], prefix='sector', drop_first=True)\n",
    "    df_features = pd.concat([df_features, sector_dummies], axis=1)\n",
    "    sector_cols = sector_dummies.columns.tolist()\n",
    "    print(f'Added {len(sector_cols)} sector dummies')\n",
    "else:\n",
    "    sector_cols = []\n",
    "\n",
    "# B) Add revenue as feature (larger companies may be more predictable)\n",
    "if 'ingresos' in df_features.columns:\n",
    "    df_features['ingresos_current'] = df_features['ingresos']\n",
    "\n",
    "# C) Add profitability ratios from lag_1 (profit margin trend)\n",
    "if 'ganancia_lag_1' in df_features.columns and 'ingresos_lag_1' in df_features.columns:\n",
    "    # Avoid division by zero\n",
    "    df_features['margin_lag_1'] = df_features['ganancia_lag_1'] / (df_features['ingresos_lag_1'].replace(0, np.nan) + 1e-3)\n",
    "    df_features['margin_lag_1'] = df_features['margin_lag_1'].fillna(0)\n",
    "    print('Added profit margin from lag_1')\n",
    "\n",
    "# D) Add volatility indicator (if company had very different profits, harder to predict)\n",
    "if 'ganancia_lag_1' in df_features.columns and 'ganancia_lag_2' in df_features.columns:\n",
    "    df_features['ganancia_volatility'] = (df_features['ganancia_lag_1'] - df_features['ganancia_lag_2']).abs()\n",
    "    df_features['ganancia_volatility'] = df_features['ganancia_volatility'].fillna(0)\n",
    "    print('Added profit volatility feature')\n",
    "\n",
    "# E) Add company size category (small/medium/large based on revenue)\n",
    "if 'ingresos' in df_features.columns:\n",
    "    df_features['size_category'] = pd.qcut(df_features['ingresos'].rank(method='first'),\n",
    "                                            q=3, labels=['small','medium','large'], duplicates='drop')\n",
    "    size_dummies = pd.get_dummies(df_features['size_category'], prefix='size', drop_first=True)\n",
    "    df_features = pd.concat([df_features, size_dummies], axis=1)\n",
    "    size_cols = size_dummies.columns.tolist()\n",
    "    print(f'Added {len(size_cols)} size category dummies')\n",
    "\n",
    "# Build updated feature list\n",
    "new_feature_cols = feature_cols.copy()\n",
    "new_feature_cols.extend(sector_cols)\n",
    "new_feature_cols.extend(['ingresos_current'])\n",
    "new_feature_cols.extend(['margin_lag_1', 'ganancia_volatility'])\n",
    "new_feature_cols.extend(size_cols)\n",
    "\n",
    "# Prepare updated X with new features\n",
    "X_new = df_features[new_feature_cols].copy()\n",
    "for col in X_new.columns:\n",
    "    if X_new[col].dtype == 'object':\n",
    "        X_new[col] = X_new[col].astype(int)\n",
    "    else:\n",
    "        X_new[col] = pd.to_numeric(X_new[col], errors='coerce')\n",
    "\n",
    "# Impute NaNs in new features\n",
    "from sklearn.impute import SimpleImputer\n",
    "imp_new = SimpleImputer(strategy='median')\n",
    "X_new_imputed = pd.DataFrame(imp_new.fit_transform(X_new), columns=X_new.columns)\n",
    "\n",
    "print(f'Updated feature set: {X_new_imputed.shape[0]} rows, {X_new_imputed.shape[1]} features (was {X.shape[1]})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f114bb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Use the engineered features (with sector dummies, volatility, etc.)\n",
    "# Build comprehensive feature set\n",
    "df_final = df_model.copy()\n",
    "\n",
    "# Add sector dummies\n",
    "sector_dummies = pd.get_dummies(df_final['MACROSECTOR'], prefix='sector', drop_first=True)\n",
    "df_final = pd.concat([df_final, sector_dummies], axis=1)\n",
    "sector_cols = sector_dummies.columns.tolist()\n",
    "\n",
    "# Add revenue\n",
    "df_final['ingresos_current'] = df_final['INGRESOS OPERACIONALES']\n",
    "\n",
    "# Add margin and volatility\n",
    "df_final['margin_lag_1'] = df_final['ganancia_lag_1'] / (df_final['ingresos_lag_1'].replace(0, np.nan) + 1e-3)\n",
    "df_final['margin_lag_1'] = df_final['margin_lag_1'].fillna(0)\n",
    "df_final['ganancia_volatility'] = (df_final['ganancia_lag_1'] - df_final['ganancia_lag_2']).abs().fillna(0)\n",
    "\n",
    "# Prepare final feature list\n",
    "final_feature_cols = feature_cols.copy() + sector_cols + ['ingresos_current', 'margin_lag_1', 'ganancia_volatility']\n",
    "\n",
    "# Prepare X with proper imputation\n",
    "X_final = df_final[final_feature_cols].copy()\n",
    "for col in X_final.columns:\n",
    "    X_final[col] = pd.to_numeric(X_final[col], errors='coerce')\n",
    "\n",
    "# Impute missing values\n",
    "imp_final = SimpleImputer(strategy='median')\n",
    "X_final_imputed = pd.DataFrame(imp_final.fit_transform(X_final), columns=X_final.columns)\n",
    "\n",
    "# Define targets\n",
    "y_absolute = pd.to_numeric(df_final['GANANCIA_REAL_next'], errors='coerce')\n",
    "\n",
    "y_margin = (df_final['GANANCIA_REAL_next'] / \n",
    "            (df_final['INGRESOS OPERACIONALES'].replace(0, np.nan) + 1e-3)) * 100\n",
    "y_margin = y_margin.fillna(0)\n",
    "\n",
    "print(f'\\nFeature set: {X_final_imputed.shape[0]} rows, {X_final_imputed.shape[1]} features')\n",
    "print(f'  Includes: {len(sector_cols)} sector dummies, volatility, margin, revenue features')\n",
    "\n",
    "# Train with PROFIT MARGIN target using GroupKFold\n",
    "print('\\n' + '='*80)\n",
    "print('TRAINING WITH PROFIT MARGIN TARGET (GroupKFold)')\n",
    "print('='*80)\n",
    "\n",
    "gkf_final = GroupKFold(n_splits=5)\n",
    "margin_rmses, margin_maes = [], []\n",
    "fold_num = 0\n",
    "\n",
    "for train_idx, val_idx in gkf_final.split(X_final_imputed, groups=df_final['NIT'].values):\n",
    "    fold_num += 1\n",
    "    X_tr = X_final_imputed.iloc[train_idx]\n",
    "    X_val = X_final_imputed.iloc[val_idx]\n",
    "    y_tr = y_margin.values[train_idx]\n",
    "    y_val = y_margin.values[val_idx]\n",
    "    \n",
    "    val_nits = df_final.iloc[val_idx]['NIT'].nunique()\n",
    "    \n",
    "    try:\n",
    "        import lightgbm as lgb\n",
    "        dtrain = lgb.Dataset(X_tr.values, label=y_tr)\n",
    "        # Tuned params: lower learning rate, higher regularization for robustness\n",
    "        params = {\n",
    "            'objective':'regression',\n",
    "            'metric':'rmse',\n",
    "            'verbosity':-1,\n",
    "            'num_leaves':15,\n",
    "            'learning_rate':0.02,\n",
    "            'reg_alpha':0.5,\n",
    "            'reg_lambda':0.5,\n",
    "            'min_data_in_leaf':10,\n",
    "            'max_depth':6\n",
    "        }\n",
    "        bst = lgb.train(params, dtrain, num_boost_round=500)\n",
    "        preds = bst.predict(X_val.values)\n",
    "    except Exception as e:\n",
    "        imp_fold = SimpleImputer(strategy='median')\n",
    "        X_tr_imp = imp_fold.fit_transform(X_tr)\n",
    "        X_val_imp = imp_fold.transform(X_val)\n",
    "        rf = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1)\n",
    "        rf.fit(X_tr_imp, y_tr)\n",
    "        preds = rf.predict(X_val_imp)\n",
    "    \n",
    "    preds = np.asarray(preds)\n",
    "    mask_ok = ~np.isnan(preds) & ~np.isnan(y_val)\n",
    "    \n",
    "    if mask_ok.sum() > 0:\n",
    "        rmse = np.sqrt(mean_squared_error(y_val[mask_ok], preds[mask_ok]))\n",
    "        mae = mean_absolute_error(y_val[mask_ok], preds[mask_ok])\n",
    "        margin_rmses.append(rmse)\n",
    "        margin_maes.append(mae)\n",
    "        print(f'Fold {fold_num}: RMSE {rmse:.2f}%, MAE {mae:.2f}% | Val NITs: {val_nits}')\n",
    "\n",
    "if margin_rmses:\n",
    "    mean_rmse = np.mean(margin_rmses)\n",
    "    std_rmse = np.std(margin_rmses)\n",
    "    mean_mae = np.mean(margin_maes)\n",
    "    std_mae = np.std(margin_maes)\n",
    "    \n",
    "    print(f'\\n✓ PROFIT MARGIN GroupKFold Results:')\n",
    "    print(f'  CV Mean RMSE: {mean_rmse:.2f}% (+/- {std_rmse:.2f}%)')\n",
    "    print(f'  CV Mean MAE:  {mean_mae:.2f}% (+/- {std_mae:.2f}%)')\n",
    "    print(f'  Improvement: Std Dev {std_rmse:.2f} (vs {np.std(gkf_rmses):.2f} for absolute profit)')\n",
    "    \n",
    "    if std_rmse < np.std(gkf_rmses):\n",
    "        print(f'\\n MARGIN TARGET IS MORE STABLE (+{((np.std(gkf_rmses) - std_rmse) / np.std(gkf_rmses) * 100):.1f}% improvement)')\n",
    "    else:\n",
    "        print(f'\\n Margin still unstable; consider sector-specific models')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
